{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "This notebook will demonstrate an implementation of a neural network using the Multilayer Perceptron with the [IBMEmployeeAttrition](https://github.com/Madison-Bunting/INDE-577/blob/main/IBMEmployeeAttrition.csv) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always include important imports at the top\n",
    "import numpy as np #for linear algebra functions\n",
    "import pandas as pd #for data processing the CSV\n",
    "from tensorflow import keras\n",
    "\n",
    "#visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset as a dataframe\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Madison-Bunting/INDE-577/main/IBMEmployeeAttrition.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data by removing variables with zero variance (as uncovered in the [Exploring A New Dataset](https://github.com/Madison-Bunting/INDE-577/blob/main/Exploring%20a%20New%20Dataset.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop variables with zero variance: EmployeeCount, Over18, and StandardHours\n",
    "df.drop('EmployeeCount', axis = 1, inplace = True)\n",
    "df.drop('Over18', axis = 1, inplace = True)\n",
    "df.drop('StandardHours', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlated variables will impact the perceptron's outputs, so those should be dropped as well. As uncovered in the [Exploring A New Dataset](https://github.com/Madison-Bunting/INDE-577/blob/main/Exploring%20a%20New%20Dataset.ipynb) Notebook, we should drop Job Level, Total Working Years, Years in Current Role, Years with Current Manager, and Percent Salary Hike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19479</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>24907</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2396</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>23159</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>16632</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1466</td>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>2061</td>\n",
       "      <td>...</td>\n",
       "      <td>12290</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1467</td>\n",
       "      <td>39</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>613</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>2062</td>\n",
       "      <td>...</td>\n",
       "      <td>21457</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1468</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>155</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2064</td>\n",
       "      <td>...</td>\n",
       "      <td>5174</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1469</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1023</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>13243</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1470</td>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>628</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>2068</td>\n",
       "      <td>...</td>\n",
       "      <td>10228</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Age Attrition     BusinessTravel  DailyRate  \\\n",
       "0         1   41       Yes      Travel_Rarely       1102   \n",
       "1         2   49        No  Travel_Frequently        279   \n",
       "2         3   37       Yes      Travel_Rarely       1373   \n",
       "3         4   33        No  Travel_Frequently       1392   \n",
       "4         5   27        No      Travel_Rarely        591   \n",
       "...     ...  ...       ...                ...        ...   \n",
       "1465   1466   36        No  Travel_Frequently        884   \n",
       "1466   1467   39        No      Travel_Rarely        613   \n",
       "1467   1468   27        No      Travel_Rarely        155   \n",
       "1468   1469   49        No  Travel_Frequently       1023   \n",
       "1469   1470   34        No      Travel_Rarely        628   \n",
       "\n",
       "                  Department  DistanceFromHome  Education EducationField  \\\n",
       "0                      Sales                 1          2  Life Sciences   \n",
       "1     Research & Development                 8          1  Life Sciences   \n",
       "2     Research & Development                 2          2          Other   \n",
       "3     Research & Development                 3          4  Life Sciences   \n",
       "4     Research & Development                 2          1        Medical   \n",
       "...                      ...               ...        ...            ...   \n",
       "1465  Research & Development                23          2        Medical   \n",
       "1466  Research & Development                 6          1        Medical   \n",
       "1467  Research & Development                 4          3  Life Sciences   \n",
       "1468                   Sales                 2          3        Medical   \n",
       "1469  Research & Development                 8          3        Medical   \n",
       "\n",
       "      EmployeeNumber  ...  MonthlyRate NumCompaniesWorked  OverTime  \\\n",
       "0                  1  ...        19479                  8       Yes   \n",
       "1                  2  ...        24907                  1        No   \n",
       "2                  4  ...         2396                  6       Yes   \n",
       "3                  5  ...        23159                  1       Yes   \n",
       "4                  7  ...        16632                  9        No   \n",
       "...              ...  ...          ...                ...       ...   \n",
       "1465            2061  ...        12290                  4        No   \n",
       "1466            2062  ...        21457                  4        No   \n",
       "1467            2064  ...         5174                  1       Yes   \n",
       "1468            2065  ...        13243                  2        No   \n",
       "1469            2068  ...        10228                  2        No   \n",
       "\n",
       "      PerformanceRating RelationshipSatisfaction  StockOptionLevel  \\\n",
       "0                     3                        1                 0   \n",
       "1                     4                        4                 1   \n",
       "2                     3                        2                 0   \n",
       "3                     3                        3                 0   \n",
       "4                     3                        4                 1   \n",
       "...                 ...                      ...               ...   \n",
       "1465                  3                        3                 1   \n",
       "1466                  3                        1                 1   \n",
       "1467                  4                        2                 1   \n",
       "1468                  3                        4                 0   \n",
       "1469                  3                        1                 0   \n",
       "\n",
       "     TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \\\n",
       "0                        0                1               6   \n",
       "1                        3                3              10   \n",
       "2                        3                3               0   \n",
       "3                        3                3               8   \n",
       "4                        3                3               2   \n",
       "...                    ...              ...             ...   \n",
       "1465                     3                3               5   \n",
       "1466                     5                3               7   \n",
       "1467                     0                3               6   \n",
       "1468                     3                2               9   \n",
       "1469                     3                4               4   \n",
       "\n",
       "      YearsSinceLastPromotion  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           3  \n",
       "4                           2  \n",
       "...                       ...  \n",
       "1465                        0  \n",
       "1466                        1  \n",
       "1467                        0  \n",
       "1468                        0  \n",
       "1469                        1  \n",
       "\n",
       "[1470 rows x 28 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping variables listed above that are correlated\n",
    "df_final = df.drop(['JobLevel','TotalWorkingYears','YearsInCurrentRole', 'YearsWithCurrManager' , 'PercentSalaryHike'], axis=1)\n",
    "#Confirm those variables were sucessfully dropped\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "Before we can create a multi-layer perceptron with this dataset, we need to pre-process the data and encode labels. We will do this using sklearn's preprocessing package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function which takes the dataset as input and ouputs the processed dataset\n",
    "def preprocessor(df):\n",
    "    res_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    res_df['BusinessTravel'] = le.fit_transform(res_df['BusinessTravel'])\n",
    "    res_df['Department'] = le.fit_transform(res_df['Department'])\n",
    "    res_df['Education'] = le.fit_transform(res_df['Education'])\n",
    "    res_df['EducationField'] = le.fit_transform(res_df['EducationField'])\n",
    "    res_df['JobRole'] = le.fit_transform(res_df['JobRole'])\n",
    "    res_df['Gender'] = le.fit_transform(res_df['Gender'])\n",
    "    res_df['MaritalStatus'] = le.fit_transform(res_df['MaritalStatus'])\n",
    "    res_df['OverTime'] = le.fit_transform(res_df['OverTime'])\n",
    "    res_df['Attrition'] = le.fit_transform(res_df['Attrition'])\n",
    "    return res_df\n",
    "\n",
    "#Run the function on the desired dataset\n",
    "encoded_df = preprocessor(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to select which features we want to use with SVM and standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1465    0\n",
       "1466    0\n",
       "1467    0\n",
       "1468    0\n",
       "1469    0\n",
       "Name: Attrition, Length: 1470, dtype: int32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting features\n",
    "X = encoded_df.drop(['Attrition'],axis =1)\n",
    "y = encoded_df['Attrition']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: (0, 0)\n",
      "Standard deviation: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Standardizing features\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "#Confirm the new mean and standard deviation of the dataset\n",
    "mean = np.mean(X, axis=0)\n",
    "print('Mean: (%d, %d)' % (mean[0], mean[1]))\n",
    "standard_deviation = np.std(X, axis=0)\n",
    "print('Standard deviation: (%d, %d)' % (standard_deviation[0], standard_deviation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(13, 13, 13), max_iter=500)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y will temp store one-hot encoded label vectors\n",
    "Y = []\n",
    "for y in y_train:\n",
    "    temp_vec = np.zeros((10, 1))\n",
    "    temp_vec[y][0] = 1.0\n",
    "    Y.append(temp_vec)\n",
    "\n",
    "# Our data will be stored as a list of tuples. \n",
    "train_data = [p for p in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron():\n",
    "  \n",
    "    def __init__(self, layers = [784, 60, 60, 10]):\n",
    "        self.layers = layers\n",
    "        self.L = len(self.layers)\n",
    "        self.W =[[0.0]]\n",
    "        self.B = [[0.0]]\n",
    "        for i in range(1, self.L):\n",
    "            w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
    "            b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
    "\n",
    "            self.W.append(w_temp)\n",
    "            self.B.append(b_temp)\n",
    "\n",
    "    def reset_weights(self, layers = [784, 60, 60, 10]):\n",
    "        self.layers = layers\n",
    "        self.L = len(self.layers)\n",
    "        self.W = [[0.0]]\n",
    "        self.B = [[0.0]]\n",
    "        for i in range(1, self.L):\n",
    "            w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
    "            b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
    "\n",
    "            self.W.append(w_temp)\n",
    "            self.B.append(b_temp)\n",
    "\n",
    "\n",
    "    def forward_pass(self, p, predict_vector = False):\n",
    "        Z =[[0.0]]\n",
    "        A = [p[0]]\n",
    "        for i in range(1, self.L):\n",
    "            z = (self.W[i] @ A[i-1]) + self.B[i]\n",
    "            a = sigmoid(z)\n",
    "            Z.append(z)\n",
    "            A.append(a)\n",
    "\n",
    "        if predict_vector == True:\n",
    "            return A[-1]\n",
    "        else:\n",
    "            return Z, A\n",
    "\n",
    "    def MSE(self, data):\n",
    "        c = 0.0\n",
    "        for p in data:\n",
    "            a = self.forward_pass(p, predict_vector=True)\n",
    "            c += mse(a, p[1])\n",
    "        return c/len(data)\n",
    "\n",
    "    def deltas_dict(self, p):\n",
    "        Z, A = self.forward_pass(p)\n",
    "        deltas = dict()\n",
    "        deltas[self.L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
    "        for l in range(self.L-2, 0, -1):\n",
    "            deltas[l] = (self.W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
    "\n",
    "        return A, deltas\n",
    "\n",
    "    def stochastic_gradient_descent(self, data, alpha = 0.04, epochs = 3):\n",
    "        print(f\"Initial Cost = {self.MSE(data)}\")\n",
    "        for k in range(epochs):\n",
    "            for p in data:\n",
    "                A, deltas = self.deltas_dict(p)\n",
    "                for i in range(1, self.L):\n",
    "                    self.W[i] = self.W[i] - alpha*deltas[i]@A[i-1].T\n",
    "                    self.B[i] = self.B[i] - alpha*deltas[i]\n",
    "        print(f\"{k} Cost = {self.MSE(data)}\")\n",
    "\n",
    "\n",
    "    def mini_batch_gradient_descent(self, data, batch_size = 15, alpha = 0.04, epochs = 3):\n",
    "        print(f\"Initial Cost = {self.MSE(data)}\")\n",
    "        data_length = len(data)\n",
    "        for k in range(epochs):\n",
    "            for j in range(0, data_length-batch_size, batch_size):\n",
    "                delta_list = []\n",
    "                A_list = []\n",
    "                for p in data[j:j+batch_size]:\n",
    "                    A, deltas = self.deltas_dict(p)\n",
    "                    delta_list.append(deltas)\n",
    "                    A_list.append(A)\n",
    "\n",
    "            for i in range(1, self.L):\n",
    "                self.W[i] = self.W[i] - (alpha/batch_size)*sum(da[0][i]@da[1][i-1].T for da in zip(delta_list, A_list))\n",
    "                self.B[i] = self.B[i] - (alpha/batch_size)*sum(deltas[i] for deltas in delta_list)\n",
    "        print(f\"{k} Cost = {self.MSE(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MultilayerPerceptron(layers=[784, 100, 100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-57b8218047e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmini_batch_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-85b2bc50ee94>\u001b[0m in \u001b[0;36mmini_batch_gradient_descent\u001b[1;34m(self, data, batch_size, alpha, epochs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmini_batch_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.04\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Initial Cost = {self.MSE(data)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mdata_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-85b2bc50ee94>\u001b[0m in \u001b[0;36mMSE\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_vector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeltas_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "net.mini_batch_gradient_descent(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
