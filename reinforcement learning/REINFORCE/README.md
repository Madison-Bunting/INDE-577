# Reinforcement Learning

![image](https://user-images.githubusercontent.com/89811204/132997613-982173db-9d8b-4470-9a39-5e7dd7878197.png)

Reinforcement learning doesn't use an existing dataset. Instead, we create a learning system, called an **agent**, that can collect its own data through trial-and-error in an **environment** where it observes the environment, selects and perform actions, and is reinforced with a **reward** (positive) or **penalty** (negative). It then determines the best strategy, called a **policy** to maximize rewards over time that defines which actions the agent should choose in a given situation.

e.g. robots learning to walk, DeepMind's AlphaGo program to play Go, playing Dota, or playing Mario, with rewards for collecting coins and a penalty for walking into a Goomba
