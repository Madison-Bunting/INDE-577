# Reinforcement Learning

ch 18
https://github.com/ageron/handson-ml2/blob/master/18_reinforcement_learning.ipynb
python machine learning pg 35, ch 18
https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch18

![image](https://user-images.githubusercontent.com/89811204/132997613-982173db-9d8b-4470-9a39-5e7dd7878197.png)

Reinforcement learning doesn't use an existing dataset. Instead, we create a learning system, called an **agent**, that can collect its own data through trial-and-error in an **environment** where it observes the environment, selects and perform actions, and is reinforced with a **reward** (positive) or **penalty** (negative). It then determines the best strategy, called a **policy** to maximize rewards over time that defines which actions the agent should choose in a given situation.

e.g. robots learning to walk, DeepMind's AlphaGo program to play Go, playing Dota, or playing Mario, with rewards for collecting coins and a penalty for walking into a Goomba

List of reinforcement algorithms in this repository:
  - [Q-Learning](https://github.com/Madison-Bunting/INDE-577/tree/main/reinforcement%20learning/1%20-%20q-learning)
  - [Graph Theory](https://github.com/Madison-Bunting/INDE-577/tree/main/reinforcement%20learning/2%20-%20graph%20theory)
